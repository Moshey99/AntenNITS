{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from nits.model import *\n",
    "\n",
    "# device = 'cuda:3'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, arch):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = self.build_net(arch, name_str='d', linear_final_layer=True)\n",
    "            \n",
    "    def build_net(self, arch, name_str='', linear_final_layer=True):\n",
    "        net = nn.ModuleList()\n",
    "        for i, (a1, a2) in enumerate(zip(arch[:-1], arch[1:])):\n",
    "            net.append(nn.Linear(a1, a2))\n",
    "            \n",
    "            # add nonlinearities\n",
    "            if i < len(arch) - 2 or not linear_final_layer:\n",
    "                net.append(nn.ReLU())\n",
    "                \n",
    "        return net\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for l in self.layers:\n",
    "            y = l(y)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "class VAEPIN(nn.Module):\n",
    "    def __init__(self, d, arch=[512, 512], pin_arch=[8, 1], constraint_type='neg_exp',\n",
    "                 log_var_bias=-5., autoregressive=False, start=-1., end=1.):\n",
    "        super(VAEPIN, self).__init__()\n",
    "        self.d = d\n",
    "        self.arch, self.pin_arch = arch, pin_arch\n",
    "        self.constraint_type = constraint_type\n",
    "        self.autoregressive = autoregressive\n",
    "        \n",
    "        self.register_buffer('start', torch.tensor([start] * self.d).reshape(1, self.d))\n",
    "        self.register_buffer('end', torch.tensor([end] * self.d).reshape(1, self.d))\n",
    "        \n",
    "        # build PIN models\n",
    "        \n",
    "        final_constraint_type = 'softmax'\n",
    "        if autoregressive:\n",
    "            self.prior = ConditionalNITS(d=self.d, arch=[d] + pin_arch, start=start, end=end, \n",
    "                                        A_constraint=constraint_type, add_residual_connections=True,\n",
    "                                        final_layer_constraint=final_constraint_type)\n",
    "            self.posterior = ConditionalNITS(d=self.d, arch=[d] + pin_arch, start=start, end=end, \n",
    "                                        A_constraint=constraint_type, add_residual_connections=True,\n",
    "                                        final_layer_constraint=final_constraint_type)\n",
    "        else:\n",
    "            self.prior = NITS(d=self.d, arch=[1] + pin_arch, start=start, end=end, \n",
    "                             A_constraint=constraint_type, add_residual_connections=True,\n",
    "                             final_layer_constraint=final_constraint_type)\n",
    "            self.posterior = NITS(d=self.d, arch=[1] + pin_arch, start=start, end=end, \n",
    "                             A_constraint=constraint_type, add_residual_connections=True,\n",
    "                             final_layer_constraint=final_constraint_type)  \n",
    "        \n",
    "        self.prior_params = torch.nn.Parameter(torch.randn((1, self.prior.tot_params)))\n",
    "                        \n",
    "        # build FC layers\n",
    "        self.pre_encoder = MLP(arch=arch + [self.posterior.tot_params])\n",
    "        self.decoder = MLP(arch=[d] + arch[::-1])\n",
    "        \n",
    "    def parameters(self):\n",
    "        for param in self.pre_encoder.parameters():\n",
    "            yield param\n",
    "            \n",
    "        for param in self.decoder.parameters():\n",
    "            yield param\n",
    "            \n",
    "        for param in [p for p in self.prior.parameters()]:\n",
    "            yield param\n",
    "                                        \n",
    "    def sample_p_z(self, n):\n",
    "        z = self.prior.sample(n, self.prior_params)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def sample_p_x(self, n):\n",
    "        z = self.sample_p_z(n)\n",
    "        \n",
    "        x_hat = self.decode(z)\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "    def p_z(self, z):\n",
    "        p_z = self.prior.pdf(z, self.prior_params)\n",
    "        p_z = p_z.prod(axis=1, keepdim=True)\n",
    "            \n",
    "        return p_z\n",
    "    \n",
    "    def p_z_x(self, z, x):\n",
    "        posterior_params = self.pre_encoder(x).reshape(len(x), self.posterior.tot_params)\n",
    "        p_z_x = self.posterior.pdf(z, posterior_params)\n",
    "        p_z_x = p_z_x.prod(axis=1, keepdim=True)\n",
    "        \n",
    "        return p_z_x\n",
    "            \n",
    "    def encode(self, x):\n",
    "        posterior_params = self.pre_encoder(x).reshape(len(x), self.posterior.tot_params)\n",
    "        \n",
    "        z = self.posterior.sample(1, posterior_params)\n",
    "        \n",
    "        return z\n",
    "        \n",
    "    def decode(self, z):\n",
    "        x_hat = self.decoder(z)\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "    def alpha(self, t, scale=1.):\n",
    "#         t = t * np.pi / 10\n",
    "#         return torch.sigmoid(1. + torch.sin(t) * scale)\n",
    "        return torch.sigmoid(torch.tensor(0., device=device))\n",
    "    \n",
    "    def train_model(self, x, epochs=100, print_every=20, lr=1e-3, batch_size=128):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        t = torch.tensor(0., device=x.device)\n",
    "\n",
    "        sum_recon_loss = 0.\n",
    "        sum_kl_loss = 0.\n",
    "\n",
    "        for e in range(epochs):\n",
    "            alpha = self.alpha(e)\n",
    "            for i, x_ in enumerate(create_batcher(x, batch_size=batch_size)):\n",
    "                x_ = x_.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                z = model.encode(x_)\n",
    "                x_hat = model.decode(z)\n",
    "\n",
    "                recon_loss = ((x_hat - x_) ** 2).sum()\n",
    "                kl_loss = (model.p_z_x(z, x_).log() - model.p_z(z).log()).sum()\n",
    "                loss = alpha * recon_loss + (1 - alpha) * kl_loss\n",
    "                \n",
    "                t += 1\n",
    "\n",
    "                sum_kl_loss += kl_loss.detach().cpu().numpy()\n",
    "                sum_recon_loss += recon_loss.detach().cpu().numpy()\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            if e and e % print_every == 0:\n",
    "                kl_loss = sum_kl_loss / print_every / len(x)\n",
    "                recon_loss = sum_recon_loss / print_every / len(x)\n",
    "                print('kl_loss: {:.3f} | recon_loss: {:.3f} | alpha_t {:.3f}'.format(\n",
    "                    kl_loss, recon_loss, alpha))\n",
    "                sum_kl_loss, sum_recon_loss = 0., 0.\n",
    "\n",
    "def create_batcher(x, y=None, batch_size=128):\n",
    "    idx = 0\n",
    "    p = torch.randperm(len(x))\n",
    "    x = x[p]\n",
    "    \n",
    "    if y is not None:\n",
    "        y = y[p]\n",
    "    \n",
    "    while idx + batch_size < len(x):\n",
    "        if y is None:\n",
    "            yield x[idx:idx+batch_size]\n",
    "        else:\n",
    "            yield x[idx:idx+batch_size], y[idx:idx+batch_size]\n",
    "        idx += batch_size\n",
    "    else:\n",
    "        if y is None:\n",
    "            yield x[idx:]\n",
    "        else:\n",
    "            yield x[idx:], y[idx:]\n",
    "    \n",
    "def plot_n(X, n):\n",
    "    _, arr = plt.subplots(n, n)\n",
    "    arr = arr.reshape(-1)\n",
    "    X = np.random.permutation(X)\n",
    "    for i, x in enumerate(X):\n",
    "        if i == (n * n):\n",
    "            break\n",
    "        arr[i].imshow(x.reshape(28, 28), cmap='gray')\n",
    "        arr[i].axis('off')\n",
    "        \n",
    "def random_project(X, dim=2):\n",
    "    _, d = X.shape\n",
    "    P = torch.randn((d, 2), device=X.device)\n",
    "    U, _, _ = torch.linalg.svd(P, full_matrices=False)\n",
    "    \n",
    "    return X.mm(U)\n",
    "\n",
    "def top_components(X, dim=2):\n",
    "    U, _, _ = torch.linalg.svd(X, full_matrices=False)\n",
    "    \n",
    "    return U\n",
    "\n",
    "def scatter(X, method='', **kwargs):\n",
    "    if method == 'top_components':\n",
    "        X = top_components(X)\n",
    "    elif method == 'random_project':\n",
    "        X = random_project(X)\n",
    "       \n",
    "    plt.figure()\n",
    "    plt.scatter(X[:,0], X[:,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i1, i2 = 0, 1\n",
    "start, end = -3., 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "dataset = 'mnist'\n",
    "\n",
    "if dataset == 'gaussian':\n",
    "    n_gaussians = 2\n",
    "    sig = 0.1\n",
    "    torch.manual_seed(0)\n",
    "    n, D, d = 1000, 2, 1#n_gaussians\n",
    "    \n",
    "    ns = [int(n / n_gaussians)] * (n_gaussians - 1)\n",
    "    ns.append(n - np.sum(ns))\n",
    "    \n",
    "    mus = torch.randn((n_gaussians, D))\n",
    "    mus_broadcast = mus.repeat_interleave(torch.tensor(ns), axis=0)\n",
    "    \n",
    "    x = torch.randn((n, D)) * sig + mus_broadcast\n",
    "    \n",
    "    y = torch.cat([torch.ones(n, 1) * i for i, n in enumerate(ns)], axis=0).to(device)\n",
    "\n",
    "    # normalize\n",
    "    x = (x - x.min(axis=0)[0][None,:]) / (x.max(axis=0)[0][None,:] - x.min(axis=0)[0][None,:])\n",
    "    \n",
    "    scatter(x.cpu(), c=y.cpu())\n",
    "    n_classes = n_gaussians\n",
    "elif dataset == 'mnist':\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = torch.tensor(x_train), torch.tensor(x_test)\n",
    "    y_train, y_test = torch.tensor(y_train), torch.tensor(y_test)\n",
    "    x = torch.cat([x_train, x_test], axis=0).reshape(-1, 784).float() / 255.\n",
    "    y = torch.cat([y_train, y_test], axis=0)\n",
    "    \n",
    "    n, D, d = len(x), 784, 10\n",
    "    \n",
    "    plot_n(x, n=3)\n",
    "    \n",
    "    n_classes = 10\n",
    "    \n",
    "x, y = x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEPIN(d=d, arch=[D, 256, 512], \n",
    "               pin_arch=[16, 16, 1], \n",
    "               constraint_type='neg_exp',\n",
    "               autoregressive=False, \n",
    "               start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "\n",
    "x2 = torch.linspace(start, end, 300, device='cpu').reshape(-1, 1).tile((1, d))\n",
    "\n",
    "y2 = model.p_z(x2)\n",
    "    \n",
    "plt.scatter(x2[:,0].detach().cpu(), y2[:,0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.train_model(x, epochs=10000, print_every=10, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib\n",
    "model = model.to('cpu')\n",
    "# model = model.to(device)\n",
    "# RECONSTRUCTED DATA\n",
    "x_hat = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_ in create_batcher(x.cpu(), batch_size=1024):\n",
    "        z = model.encode(x_)\n",
    "        x_hat.append(model.decode(z).cpu().detach())\n",
    "        break\n",
    "    \n",
    "x_hat = torch.cat(x_hat, axis=0)\n",
    "\n",
    "plt.scatter(x[:,i1].cpu(), x[:,i2].cpu(), c='blue', alpha=0.05)\n",
    "plt.scatter(x_hat[:,i1], x_hat[:,i2], c='red', alpha=0.05)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    plot_n(x_hat, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# GENERATED DATA\n",
    "with torch.no_grad():\n",
    "    x_sampled = model.sample_p_x(1000).detach().cpu().numpy()\n",
    "\n",
    "plt.scatter(x[:,i1].cpu(), x[:,i2].cpu(), c='blue', alpha=0.05)\n",
    "plt.scatter(x_sampled[:,i1], x_sampled[:,i2], c='red', alpha=0.05)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "if dataset == 'mnist':\n",
    "    plot_n(x_sampled, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "n_steps = 300\n",
    "\n",
    "idx = 0\n",
    "\n",
    "unif_1d_x = torch.linspace(start, end, n_steps, device='cpu').reshape(-1, 1)\n",
    "zeros = torch.zeros_like(unif_1d_x) + 0.0\n",
    "\n",
    "unif_x = [zeros] * d\n",
    "unif_x[idx] = unif_1d_x\n",
    "\n",
    "unif_x = torch.cat(unif_x, axis=1)\n",
    "\n",
    "y_prior = []\n",
    "y_posteriors = [[] for n_ in range(n_classes)]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_ in unif_x:\n",
    "        y_prior.append(model.p_z(x_.reshape(1, d)))\n",
    "        for n_ in range(n_classes):\n",
    "            idx_ = n_ * int(n / n_classes)\n",
    "            y_posteriors[n_].append(model.p_z_x(x_.reshape(1, d), x[idx_][None,:].cpu()))\n",
    "\n",
    "    y_prior = torch.cat(y_prior, axis=0)\n",
    "    y_posteriors = [torch.cat(y_posterior, axis=0) for y_posterior in y_posteriors]\n",
    "    \n",
    "plt.scatter(unif_x[:,idx].detach().cpu(), y_prior[:,0].detach().cpu(), c='red', alpha=0.1)\n",
    "for y_posterior in y_posteriors:\n",
    "    plt.scatter(unif_x[:,idx].detach().cpu(), y_posterior[:,0].detach().cpu(), c='blue', alpha=0.1)\n",
    "    \n",
    "plt.ylim(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "%matplotlib inline\n",
    "\n",
    "# plot prior surface\n",
    "xs = torch.linspace(start, end, steps=100, device='cpu')\n",
    "ys = torch.linspace(start, end, steps=100, device='cpu')\n",
    "\n",
    "unif_x, unif_y = torch.meshgrid(xs, ys, indexing='xy')\n",
    "\n",
    "unif_xy = torch.cat([unif_x.unsqueeze(-1), unif_y.unsqueeze(-1)], axis=2).reshape(-1, 2)\n",
    "\n",
    "z = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = model.p_z(unif_xy)\n",
    "    \n",
    "z = z.reshape(unif_x.shape)\n",
    "    \n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(unif_x.cpu().numpy(), unif_y.cpu().numpy(), z.cpu().numpy(), cmap=cm.coolwarm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cpu')\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib import cm, colors, colorbar\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def imscatter(x, y, images, ax=None, zoom=1, colorby=None, color_mix=0.3, invert_images=False):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "        \n",
    "    if invert_images:\n",
    "        images = -images\n",
    "        \n",
    "    images = (images - images.min()) / (images.max() - images.min())\n",
    "        \n",
    "    if colorby is not None:\n",
    "        assert len(colorby) == len(images)\n",
    "        colorby = (colorby - colorby.min()) / (colorby.max() - colorby.min())\n",
    "        if len(images.shape) == 3:\n",
    "            images = images.reshape(-1, images.shape[1], images.shape[2], 1).tile((1, 1, 1, 4))\n",
    "            images[:,:,:,3] = 1.\n",
    "        norm = colors.Normalize(vmin=colorby.min(), vmax=colorby.max(), clip=True)\n",
    "        mapper = cm.ScalarMappable(norm=norm, cmap='spring')\n",
    "        a = color_mix\n",
    "        \n",
    "        images = images * (1 - a) + torch.tensor(mapper.to_rgba(colorby)).reshape(-1, 1, 1, 4) * a\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        colorbar.ColorbarBase(ax=cax, cmap=cm.get_cmap('spring'), values=sorted(colorby),\n",
    "                                 orientation=\"vertical\")\n",
    "\n",
    "    artists = []\n",
    "    for x0, y0, im0 in zip(x, y, images):\n",
    "        im0 = OffsetImage(im0, zoom=zoom, cmap=plt.cm.gray_r)\n",
    "        ab = AnnotationBbox(im0, (x0, y0), xycoords='data', frameon=False)\n",
    "        artists.append(ax.add_artist(ab))\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    \n",
    "    return artists\n",
    "\n",
    "p = torch.randperm(len(x))\n",
    "x_subset = x[p][:1000].to('cpu')\n",
    "with torch.no_grad():\n",
    "    z = model.encode(x_subset.reshape(-1, 784))\n",
    "    x_hat = model.decode(z).reshape(-1, 28, 28)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "imscatter(z[:,0], z[:,1], x_hat.numpy(), ax=ax, zoom=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot prior surface\n",
    "xs = torch.linspace(start, end, steps=40, device='cpu')\n",
    "ys = torch.linspace(start, end, steps=40, device='cpu')\n",
    "\n",
    "unif_x, unif_y = torch.meshgrid(xs, ys, indexing='xy')\n",
    "\n",
    "unif_xy = torch.cat([unif_x.unsqueeze(-1), unif_y.unsqueeze(-1)], axis=2).reshape(-1, 2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_hat = model.decode(unif_xy).cpu().reshape(-1, 28, 28)\n",
    "    z = model.p_z(unif_xy).log().cpu()\n",
    "    \n",
    "z = z.reshape(unif_x.shape)\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "imscatter(unif_x.reshape(-1).numpy(), unif_y.reshape(-1).numpy(), x_hat, ax=ax, zoom=0.5, \n",
    "          colorby=z.reshape(-1), invert_images=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
