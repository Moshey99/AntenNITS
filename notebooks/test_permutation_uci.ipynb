{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nits.model import *\n",
    "from nits.layer import *\n",
    "from nits.fc_model import *\n",
    "from nits.cnn_model import *\n",
    "from maf.datasets import *\n",
    "from nits.resmade import ResidualMADE\n",
    "    \n",
    "def create_batcher(x, batch_size=1):\n",
    "    idx = 0\n",
    "    p = torch.randperm(len(x))\n",
    "    x = x[p]\n",
    "\n",
    "    while idx + batch_size < len(x):\n",
    "        yield torch.tensor(x[idx:idx+batch_size], device=device)\n",
    "        idx += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henry/projects/NITS/nits/model.py:72: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('start_val', torch.tensor(start))\n",
      "/home/henry/projects/NITS/nits/model.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('end_val', torch.tensor(end))\n",
      "/home/henry/projects/NITS/nits/model.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('start', torch.tensor(start).reshape(1, 1).tile(1, d))\n",
      "/home/henry/projects/NITS/nits/model.py:360: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('end', torch.tensor(end).reshape(1, 1).tile(1, d))\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-d', '--dataset', type=str, default='gas')\n",
    "parser.add_argument('-g', '--gpu', type=str, default='')\n",
    "parser.add_argument('-r', '--rotate', type=bool, default=False)\n",
    "\n",
    "args = parser.parse_args(['-g', '6', '-d', 'gas'])\n",
    "\n",
    "device = 'cuda:' + args.gpu if args.gpu else 'cpu'\n",
    "print('device:', device)\n",
    "\n",
    "lr = 1e-3\n",
    "n_residual_blocks = 4\n",
    "hidden_dim = 512\n",
    "use_batch_norm = False\n",
    "zero_initialization = True\n",
    "if args.dataset == 'gas':\n",
    "    data = gas.GAS()\n",
    "    dropout_probability = 0.1\n",
    "    nits_arch = [16, 16, 1]\n",
    "    gamma = 1 - 5e-7\n",
    "elif args.dataset == 'power':\n",
    "    data = power.POWER()\n",
    "    dropout_probability = 0.1\n",
    "    nits_arch = [16, 16, 1]\n",
    "    gamma = 1 - 5e-7\n",
    "elif args.dataset == 'miniboone':\n",
    "    data = miniboone.MINIBOONE()\n",
    "    dropout_probability = 0.5\n",
    "    nits_arch = [16, 16, 1]\n",
    "    gamma = 1 - 5e-7\n",
    "elif args.dataset == 'hepmass':\n",
    "    data = hepmass.HEPMASS()\n",
    "    dropout_probability = 0.2\n",
    "    nits_arch = [16, 16, 1]\n",
    "    gamma = 1 - 5e-7\n",
    "elif args.dataset == 'bsds300':\n",
    "    data = bsds300.BSDS300()\n",
    "    dropout_probability = 0.2\n",
    "    nits_arch = [16, 16, 1]\n",
    "    gamma = 1 - 5e-7\n",
    "\n",
    "d = data.trn.x.shape[1]\n",
    "\n",
    "max_val = max(data.trn.x.max(), data.val.x.max(), data.tst.x.max())\n",
    "min_val = min(data.trn.x.min(), data.val.x.min(), data.tst.x.min())\n",
    "max_val, min_val = torch.tensor(max_val).to(device).float(), torch.tensor(min_val).to(device).float()\n",
    "\n",
    "nits_model = NITS(d=d, start=min_val, end=max_val, monotonic_const=1e-5,\n",
    "                             A_constraint='neg_exp', arch=[1] + nits_arch,\n",
    "                             final_layer_constraint='softmax',\n",
    "                             softmax_temperature=False).to(device)\n",
    "\n",
    "# model_arch = [hidden_dim] * n_residual_blocks\n",
    "# model = RotationParamModel(arch=[d] + model_arch + [nits_model.n_params], \n",
    "#                            rotate=args.rotate, nits_model=nits_model).to(device)\n",
    "# shadow = RotationParamModel(arch=[d] + model_arch + [nits_model.n_params], \n",
    "#                             rotate=args.rotate, nits_model=nits_model).to(device)\n",
    "\n",
    "model = ResMADEModel(\n",
    "    d=d, \n",
    "    rotate=args.rotate, \n",
    "    nits_model=nits_model,\n",
    "    n_residual_blocks=n_residual_blocks,\n",
    "    hidden_dim=hidden_dim,\n",
    "    dropout_probability=dropout_probability,\n",
    "    use_batch_norm=use_batch_norm,\n",
    "    zero_initialization=zero_initialization\n",
    ").to(device)\n",
    "\n",
    "shadow = ResMADEModel(\n",
    "    d=d, \n",
    "    rotate=args.rotate, \n",
    "    nits_model=nits_model,\n",
    "    n_residual_blocks=n_residual_blocks,\n",
    "    hidden_dim=hidden_dim,\n",
    "    dropout_probability=dropout_probability,\n",
    "    use_batch_norm=use_batch_norm,\n",
    "    zero_initialization=zero_initialization\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 20000\n",
    "batch_size = 512\n",
    "optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=1, gamma=gamma)\n",
    "\n",
    "# # initialize weight norm\n",
    "# for i, x in enumerate(create_batcher(data.trn.x, batch_size=batch_size)):\n",
    "#     params = model(x)\n",
    "#     break\n",
    "    \n",
    "model = EMA(model, shadow, decay=0.9995).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:    0, time: 26.03, train_ll: 3.1337, val_ll: -22.4827, lr: 9.9917e-04\n",
      "epoch:   10, time: 260.53, train_ll: 10.3799, val_ll: 11.1316, lr: 9.9089e-04\n",
      "epoch:   20, time: 284.85, train_ll: 11.0317, val_ll: 11.8190, lr: 9.8268e-04\n",
      "epoch:   30, time: 302.61, train_ll: 11.3194, val_ll: 12.0902, lr: 9.7454e-04\n",
      "epoch:   40, time: 301.44, train_ll: 11.5056, val_ll: 12.2510, lr: 9.6646e-04\n",
      "epoch:   50, time: 301.64, train_ll: 11.6294, val_ll: 12.3559, lr: 9.5846e-04\n",
      "epoch:   60, time: 301.92, train_ll: 11.7186, val_ll: 12.4282, lr: 9.5051e-04\n",
      "epoch:   70, time: 303.94, train_ll: 11.7954, val_ll: 12.4859, lr: 9.4264e-04\n",
      "epoch:   80, time: 301.64, train_ll: 11.8577, val_ll: 12.5333, lr: 9.3483e-04\n",
      "epoch:   90, time: 303.10, train_ll: 11.9096, val_ll: 12.5716, lr: 9.2708e-04\n",
      "epoch:  100, time: 302.85, train_ll: 11.9554, val_ll: 12.6047, lr: 9.1940e-04\n",
      "epoch:  110, time: 302.97, train_ll: 11.9950, val_ll: 12.6324, lr: 9.1178e-04\n",
      "epoch:  120, time: 302.56, train_ll: 12.0337, val_ll: 12.6604, lr: 9.0423e-04\n",
      "epoch:  130, time: 302.97, train_ll: 12.0683, val_ll: 12.6806, lr: 8.9674e-04\n",
      "epoch:  140, time: 301.65, train_ll: 12.0981, val_ll: 12.7022, lr: 8.8931e-04\n",
      "epoch:  150, time: 303.08, train_ll: 12.1232, val_ll: 12.7193, lr: 8.8194e-04\n",
      "epoch:  160, time: 302.68, train_ll: 12.1466, val_ll: 12.7325, lr: 8.7463e-04\n",
      "epoch:  170, time: 300.88, train_ll: 12.1693, val_ll: 12.7482, lr: 8.6739e-04\n",
      "epoch:  180, time: 302.13, train_ll: 12.1968, val_ll: 12.7614, lr: 8.6020e-04\n",
      "epoch:  190, time: 304.77, train_ll: 12.2138, val_ll: 12.7735, lr: 8.5307e-04\n",
      "epoch:  200, time: 302.49, train_ll: 12.2336, val_ll: 12.7831, lr: 8.4600e-04\n",
      "epoch:  210, time: 300.58, train_ll: 12.2541, val_ll: 12.7942, lr: 8.3899e-04\n",
      "epoch:  220, time: 298.53, train_ll: 12.2711, val_ll: 12.8036, lr: 8.3204e-04\n",
      "epoch:  230, time: 298.55, train_ll: 12.2752, val_ll: 12.8094, lr: 8.2515e-04\n",
      "epoch:  240, time: 302.97, train_ll: 12.2952, val_ll: 12.8220, lr: 8.1831e-04\n",
      "epoch:  250, time: 301.90, train_ll: 12.3078, val_ll: 12.8254, lr: 8.1153e-04\n",
      "epoch:  260, time: 301.33, train_ll: 12.3283, val_ll: 12.8356, lr: 8.0481e-04\n",
      "epoch:  270, time: 302.98, train_ll: 12.3396, val_ll: 12.8444, lr: 7.9814e-04\n",
      "epoch:  280, time: 299.94, train_ll: 12.3543, val_ll: 12.8487, lr: 7.9153e-04\n",
      "epoch:  290, time: 294.92, train_ll: 12.3671, val_ll: 12.8538, lr: 7.8497e-04\n",
      "epoch:  300, time: 294.11, train_ll: 12.3783, val_ll: 12.8636, lr: 7.7846e-04\n",
      "epoch:  310, time: 295.98, train_ll: 12.3740, val_ll: 12.8634, lr: 7.7201e-04\n",
      "epoch:  320, time: 292.74, train_ll: 12.3978, val_ll: 12.8722, lr: 7.6562e-04\n",
      "epoch:  330, time: 293.08, train_ll: 12.4162, val_ll: 12.8784, lr: 7.5927e-04\n",
      "epoch:  340, time: 292.44, train_ll: 12.4208, val_ll: 12.8829, lr: 7.5298e-04\n",
      "epoch:  350, time: 295.82, train_ll: 12.4259, val_ll: 12.8886, lr: 7.4674e-04\n",
      "epoch:  360, time: 295.79, train_ll: 12.4455, val_ll: 12.8926, lr: 7.4056e-04\n",
      "epoch:  370, time: 297.86, train_ll: 12.4550, val_ll: 12.8958, lr: 7.3442e-04\n",
      "epoch:  380, time: 294.99, train_ll: 12.4573, val_ll: 12.9032, lr: 7.2834e-04\n",
      "epoch:  390, time: 294.36, train_ll: 12.4684, val_ll: 12.9085, lr: 7.2230e-04\n",
      "epoch:  400, time: 295.28, train_ll: 12.4774, val_ll: 12.9098, lr: 7.1632e-04\n",
      "epoch:  410, time: 295.57, train_ll: 12.4922, val_ll: 12.9143, lr: 7.1038e-04\n",
      "epoch:  420, time: 294.33, train_ll: 12.4965, val_ll: 12.9158, lr: 7.0450e-04\n",
      "epoch:  430, time: 298.26, train_ll: 12.5082, val_ll: 12.9218, lr: 6.9866e-04\n",
      "epoch:  440, time: 296.32, train_ll: 12.5118, val_ll: 12.9265, lr: 6.9287e-04\n",
      "epoch:  450, time: 293.92, train_ll: 12.5218, val_ll: 12.9312, lr: 6.8713e-04\n",
      "epoch:  460, time: 295.65, train_ll: 12.5273, val_ll: 12.9307, lr: 6.8144e-04\n",
      "epoch:  470, time: 296.52, train_ll: 12.5390, val_ll: 12.9359, lr: 6.7579e-04\n",
      "epoch:  480, time: 294.31, train_ll: 12.5429, val_ll: 12.9385, lr: 6.7019e-04\n",
      "epoch:  490, time: 296.69, train_ll: 12.5505, val_ll: 12.9401, lr: 6.6464e-04\n",
      "epoch:  500, time: 297.33, train_ll: 12.5572, val_ll: 12.9426, lr: 6.5913e-04\n",
      "epoch:  510, time: 293.77, train_ll: 12.5558, val_ll: 12.9467, lr: 6.5367e-04\n",
      "epoch:  520, time: 296.84, train_ll: 12.5692, val_ll: 12.9505, lr: 6.4825e-04\n",
      "epoch:  530, time: 295.15, train_ll: 12.5853, val_ll: 12.9534, lr: 6.4288e-04\n",
      "epoch:  540, time: 295.14, train_ll: 12.5777, val_ll: 12.9529, lr: 6.3756e-04\n",
      "epoch:  550, time: 293.54, train_ll: 12.5965, val_ll: 12.9565, lr: 6.3227e-04\n",
      "epoch:  560, time: 299.01, train_ll: 12.6024, val_ll: 12.9610, lr: 6.2704e-04\n",
      "epoch:  570, time: 294.30, train_ll: 12.6070, val_ll: 12.9609, lr: 6.2184e-04\n",
      "epoch:  580, time: 296.36, train_ll: 12.6147, val_ll: 12.9652, lr: 6.1669e-04\n",
      "epoch:  590, time: 296.39, train_ll: 12.6220, val_ll: 12.9687, lr: 6.1158e-04\n",
      "epoch:  600, time: 294.83, train_ll: 12.6253, val_ll: 12.9665, lr: 6.0651e-04\n",
      "epoch:  610, time: 294.84, train_ll: 12.6291, val_ll: 12.9732, lr: 6.0149e-04\n",
      "epoch:  620, time: 301.19, train_ll: 12.6353, val_ll: 12.9731, lr: 5.9650e-04\n",
      "epoch:  630, time: 299.23, train_ll: 12.6417, val_ll: 12.9747, lr: 5.9156e-04\n",
      "epoch:  640, time: 296.24, train_ll: 12.6496, val_ll: 12.9772, lr: 5.8666e-04\n",
      "epoch:  650, time: 299.08, train_ll: 12.6512, val_ll: 12.9801, lr: 5.8180e-04\n",
      "epoch:  660, time: 297.20, train_ll: 12.6624, val_ll: 12.9823, lr: 5.7698e-04\n",
      "epoch:  670, time: 294.10, train_ll: 12.6647, val_ll: 12.9834, lr: 5.7220e-04\n",
      "epoch:  680, time: 298.32, train_ll: 12.6725, val_ll: 12.9861, lr: 5.6746e-04\n",
      "epoch:  690, time: 295.90, train_ll: 12.6753, val_ll: 12.9883, lr: 5.6275e-04\n",
      "epoch:  700, time: 295.24, train_ll: 12.6849, val_ll: 12.9928, lr: 5.5809e-04\n",
      "epoch:  710, time: 294.74, train_ll: 12.6875, val_ll: 12.9929, lr: 5.5347e-04\n",
      "epoch:  720, time: 294.25, train_ll: 12.6903, val_ll: 12.9962, lr: 5.4888e-04\n",
      "epoch:  730, time: 295.95, train_ll: 12.6994, val_ll: 12.9965, lr: 5.4433e-04\n",
      "epoch:  740, time: 300.15, train_ll: 12.7050, val_ll: 12.9995, lr: 5.3982e-04\n",
      "epoch:  750, time: 296.66, train_ll: 12.7104, val_ll: 12.9996, lr: 5.3535e-04\n",
      "epoch:  760, time: 295.37, train_ll: 12.7131, val_ll: 12.9999, lr: 5.3092e-04\n",
      "epoch:  770, time: 295.71, train_ll: 12.7195, val_ll: 13.0031, lr: 5.2652e-04\n",
      "epoch:  780, time: 294.55, train_ll: 12.7163, val_ll: 13.0042, lr: 5.2215e-04\n",
      "epoch:  790, time: 295.31, train_ll: 12.7266, val_ll: 13.0086, lr: 5.1783e-04\n",
      "epoch:  800, time: 299.48, train_ll: 12.7356, val_ll: 13.0101, lr: 5.1354e-04\n",
      "epoch:  810, time: 299.38, train_ll: 12.7450, val_ll: 13.0119, lr: 5.0928e-04\n",
      "epoch:  820, time: 295.31, train_ll: 12.7445, val_ll: 13.0144, lr: 5.0506e-04\n",
      "epoch:  830, time: 297.70, train_ll: 12.7529, val_ll: 13.0181, lr: 5.0088e-04\n",
      "epoch:  840, time: 296.70, train_ll: 12.7525, val_ll: 13.0188, lr: 4.9673e-04\n",
      "epoch:  850, time: 294.73, train_ll: 12.7621, val_ll: 13.0214, lr: 4.9261e-04\n",
      "epoch:  860, time: 295.76, train_ll: 12.7692, val_ll: 13.0215, lr: 4.8853e-04\n",
      "epoch:  870, time: 298.13, train_ll: 12.7663, val_ll: 13.0234, lr: 4.8448e-04\n",
      "epoch:  880, time: 294.36, train_ll: 12.7756, val_ll: 13.0251, lr: 4.8047e-04\n",
      "epoch:  890, time: 291.90, train_ll: 12.7704, val_ll: 13.0239, lr: 4.7649e-04\n",
      "epoch:  900, time: 293.46, train_ll: 12.7800, val_ll: 13.0263, lr: 4.7254e-04\n",
      "epoch:  910, time: 295.67, train_ll: 12.7841, val_ll: 13.0303, lr: 4.6863e-04\n",
      "epoch:  920, time: 297.05, train_ll: 12.7888, val_ll: 13.0267, lr: 4.6474e-04\n",
      "epoch:  930, time: 301.44, train_ll: 12.7959, val_ll: 13.0307, lr: 4.6089e-04\n",
      "epoch:  940, time: 298.80, train_ll: 12.7970, val_ll: 13.0307, lr: 4.5707e-04\n",
      "epoch:  950, time: 297.48, train_ll: 12.8035, val_ll: 13.0325, lr: 4.5329e-04\n",
      "epoch:  960, time: 294.83, train_ll: 12.8026, val_ll: 13.0347, lr: 4.4953e-04\n",
      "epoch:  970, time: 293.75, train_ll: 12.8120, val_ll: 13.0348, lr: 4.4581e-04\n",
      "epoch:  980, time: 297.15, train_ll: 12.8136, val_ll: 13.0339, lr: 4.4211e-04\n",
      "epoch:  990, time: 299.33, train_ll: 12.8205, val_ll: 13.0375, lr: 4.3845e-04\n",
      "epoch: 1000, time: 295.21, train_ll: 12.8207, val_ll: 13.0371, lr: 4.3482e-04\n",
      "epoch: 1010, time: 297.95, train_ll: 12.8286, val_ll: 13.0410, lr: 4.3121e-04\n",
      "epoch: 1020, time: 295.40, train_ll: 12.8272, val_ll: 13.0404, lr: 4.2764e-04\n",
      "epoch: 1030, time: 297.02, train_ll: 12.8328, val_ll: 13.0415, lr: 4.2410e-04\n",
      "epoch: 1040, time: 296.44, train_ll: 12.8350, val_ll: 13.0442, lr: 4.2058e-04\n",
      "epoch: 1050, time: 299.54, train_ll: 12.8415, val_ll: 13.0440, lr: 4.1710e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1060, time: 295.55, train_ll: 12.8467, val_ll: 13.0453, lr: 4.1364e-04\n",
      "epoch: 1070, time: 295.83, train_ll: 12.8493, val_ll: 13.0439, lr: 4.1022e-04\n",
      "epoch: 1080, time: 295.79, train_ll: 12.8376, val_ll: 13.0433, lr: 4.0682e-04\n",
      "epoch: 1090, time: 295.95, train_ll: 12.8585, val_ll: 13.0470, lr: 4.0345e-04\n",
      "epoch: 1100, time: 300.21, train_ll: 12.8616, val_ll: 13.0486, lr: 4.0010e-04\n",
      "epoch: 1110, time: 303.70, train_ll: 12.8624, val_ll: 13.0492, lr: 3.9679e-04\n",
      "epoch: 1120, time: 298.02, train_ll: 12.8633, val_ll: 13.0491, lr: 3.9350e-04\n",
      "epoch: 1130, time: 296.64, train_ll: 12.8720, val_ll: 13.0516, lr: 3.9024e-04\n",
      "epoch: 1140, time: 296.45, train_ll: 12.8709, val_ll: 13.0525, lr: 3.8701e-04\n",
      "epoch: 1150, time: 297.88, train_ll: 12.8760, val_ll: 13.0541, lr: 3.8380e-04\n",
      "epoch: 1160, time: 299.14, train_ll: 12.8774, val_ll: 13.0524, lr: 3.8062e-04\n",
      "epoch: 1170, time: 299.87, train_ll: 12.8825, val_ll: 13.0534, lr: 3.7747e-04\n",
      "epoch: 1180, time: 293.21, train_ll: 12.8863, val_ll: 13.0537, lr: 3.7434e-04\n",
      "epoch: 1190, time: 291.03, train_ll: 12.8866, val_ll: 13.0542, lr: 3.7124e-04\n",
      "epoch: 1200, time: 292.08, train_ll: 12.8909, val_ll: 13.0549, lr: 3.6816e-04\n",
      "epoch: 1210, time: 293.73, train_ll: 12.8940, val_ll: 13.0555, lr: 3.6511e-04\n",
      "epoch: 1220, time: 296.34, train_ll: 12.8984, val_ll: 13.0579, lr: 3.6209e-04\n",
      "epoch: 1230, time: 300.42, train_ll: 12.9008, val_ll: 13.0574, lr: 3.5909e-04\n",
      "epoch: 1240, time: 296.17, train_ll: 12.9042, val_ll: 13.0585, lr: 3.5611e-04\n",
      "epoch: 1250, time: 296.55, train_ll: 12.9037, val_ll: 13.0581, lr: 3.5316e-04\n",
      "epoch: 1260, time: 296.26, train_ll: 12.9056, val_ll: 13.0589, lr: 3.5023e-04\n",
      "epoch: 1270, time: 295.77, train_ll: 12.9119, val_ll: 13.0603, lr: 3.4733e-04\n",
      "epoch: 1280, time: 295.94, train_ll: 12.9156, val_ll: 13.0611, lr: 3.4445e-04\n",
      "epoch: 1290, time: 300.34, train_ll: 12.9208, val_ll: 13.0617, lr: 3.4160e-04\n",
      "epoch: 1300, time: 297.55, train_ll: 12.9173, val_ll: 13.0615, lr: 3.3877e-04\n",
      "epoch: 1310, time: 295.84, train_ll: 12.9228, val_ll: 13.0626, lr: 3.3596e-04\n",
      "epoch: 1320, time: 295.79, train_ll: 12.9275, val_ll: 13.0622, lr: 3.3318e-04\n",
      "epoch: 1330, time: 297.24, train_ll: 12.9271, val_ll: 13.0647, lr: 3.3042e-04\n",
      "epoch: 1340, time: 294.81, train_ll: 12.9322, val_ll: 13.0649, lr: 3.2768e-04\n",
      "epoch: 1350, time: 300.23, train_ll: 12.9394, val_ll: 13.0635, lr: 3.2497e-04\n",
      "epoch: 1360, time: 295.99, train_ll: 12.9386, val_ll: 13.0641, lr: 3.2227e-04\n",
      "epoch: 1370, time: 296.33, train_ll: 12.9419, val_ll: 13.0661, lr: 3.1960e-04\n",
      "epoch: 1380, time: 295.74, train_ll: 12.9440, val_ll: 13.0656, lr: 3.1696e-04\n",
      "epoch: 1390, time: 292.70, train_ll: 12.9464, val_ll: 13.0677, lr: 3.1433e-04\n",
      "epoch: 1400, time: 296.96, train_ll: 12.9498, val_ll: 13.0674, lr: 3.1173e-04\n",
      "epoch: 1410, time: 301.39, train_ll: 12.9503, val_ll: 13.0657, lr: 3.0914e-04\n",
      "epoch: 1420, time: 297.61, train_ll: 12.9530, val_ll: 13.0691, lr: 3.0658e-04\n",
      "epoch: 1430, time: 296.06, train_ll: 12.9574, val_ll: 13.0690, lr: 3.0404e-04\n",
      "epoch: 1440, time: 296.80, train_ll: 12.9628, val_ll: 13.0696, lr: 3.0152e-04\n",
      "epoch: 1450, time: 298.51, train_ll: 12.9625, val_ll: 13.0694, lr: 2.9902e-04\n",
      "epoch: 1460, time: 296.07, train_ll: 12.9655, val_ll: 13.0702, lr: 2.9655e-04\n",
      "epoch: 1470, time: 296.92, train_ll: 12.9679, val_ll: 13.0706, lr: 2.9409e-04\n",
      "epoch: 1480, time: 299.99, train_ll: 12.9706, val_ll: 13.0706, lr: 2.9165e-04\n",
      "epoch: 1490, time: 296.83, train_ll: 12.9706, val_ll: 13.0717, lr: 2.8924e-04\n",
      "epoch: 1500, time: 296.00, train_ll: 12.9733, val_ll: 13.0701, lr: 2.8684e-04\n",
      "epoch: 1510, time: 296.96, train_ll: 12.9773, val_ll: 13.0718, lr: 2.8446e-04\n",
      "epoch: 1520, time: 295.69, train_ll: 12.9764, val_ll: 13.0718, lr: 2.8211e-04\n",
      "epoch: 1530, time: 295.74, train_ll: 12.9808, val_ll: 13.0733, lr: 2.7977e-04\n",
      "epoch: 1540, time: 299.78, train_ll: 12.9790, val_ll: 13.0729, lr: 2.7745e-04\n",
      "epoch: 1550, time: 295.87, train_ll: 12.9838, val_ll: 13.0748, lr: 2.7515e-04\n",
      "epoch: 1560, time: 296.49, train_ll: 12.9905, val_ll: 13.0742, lr: 2.7287e-04\n",
      "epoch: 1570, time: 295.42, train_ll: 12.9891, val_ll: 13.0762, lr: 2.7061e-04\n",
      "epoch: 1580, time: 294.23, train_ll: 12.9935, val_ll: 13.0761, lr: 2.6837e-04\n",
      "epoch: 1590, time: 295.89, train_ll: 12.9931, val_ll: 13.0746, lr: 2.6615e-04\n",
      "epoch: 1600, time: 297.65, train_ll: 12.9981, val_ll: 13.0775, lr: 2.6394e-04\n",
      "epoch: 1610, time: 297.39, train_ll: 12.9996, val_ll: 13.0777, lr: 2.6175e-04\n",
      "epoch: 1620, time: 296.42, train_ll: 13.0015, val_ll: 13.0744, lr: 2.5958e-04\n",
      "epoch: 1630, time: 296.82, train_ll: 13.0058, val_ll: 13.0776, lr: 2.5743e-04\n",
      "epoch: 1640, time: 295.18, train_ll: 13.0055, val_ll: 13.0788, lr: 2.5530e-04\n",
      "epoch: 1650, time: 293.66, train_ll: 13.0080, val_ll: 13.0791, lr: 2.5319e-04\n",
      "epoch: 1660, time: 295.59, train_ll: 13.0117, val_ll: 13.0791, lr: 2.5109e-04\n",
      "epoch: 1670, time: 295.72, train_ll: 13.0142, val_ll: 13.0784, lr: 2.4901e-04\n",
      "epoch: 1680, time: 295.83, train_ll: 13.0109, val_ll: 13.0793, lr: 2.4694e-04\n",
      "epoch: 1690, time: 298.02, train_ll: 13.0152, val_ll: 13.0796, lr: 2.4490e-04\n",
      "epoch: 1700, time: 297.93, train_ll: 13.0184, val_ll: 13.0817, lr: 2.4287e-04\n",
      "epoch: 1710, time: 298.23, train_ll: 13.0221, val_ll: 13.0796, lr: 2.4086e-04\n",
      "epoch: 1720, time: 301.05, train_ll: 13.0232, val_ll: 13.0796, lr: 2.3886e-04\n",
      "epoch: 1730, time: 298.30, train_ll: 13.0273, val_ll: 13.0814, lr: 2.3688e-04\n",
      "epoch: 1740, time: 297.81, train_ll: 13.0280, val_ll: 13.0797, lr: 2.3492e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c8481cf0684b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_batcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0morig_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-4cef7edf7485>\u001b[0m in \u001b[0;36mcreate_batcher\u001b[0;34m(x, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_ = time.time()\n",
    "for epoch in range(max_epochs):\n",
    "    model.train()\n",
    "    train_ll = 0.\n",
    "    for i, x in enumerate(create_batcher(data.trn.x, batch_size=batch_size)):\n",
    "        orig_x = x.cpu().detach().clone()\n",
    "        ll = model(x)\n",
    "        optim.zero_grad()\n",
    "        (-ll).backward()\n",
    "        train_ll += ll.detach().cpu().numpy()\n",
    "\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "        model.update()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        # compute train loss\n",
    "        train_ll /= i * batch_size\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            val_ll = 0.\n",
    "            lr = optim.param_groups[0]['lr']\n",
    "            for i, x in enumerate(create_batcher(data.val.x, batch_size=batch_size)):\n",
    "                x = torch.tensor(x, device=device)\n",
    "                ll = model(x)\n",
    "                val_ll += ll.detach().cpu().numpy()\n",
    "\n",
    "            val_ll /= i * batch_size\n",
    "            fmt_str1 = 'epoch: {:4d}, time: {:.2f}, train_ll: {:.4f},'\n",
    "            fmt_str2 = ' val_ll: {:.4f}, lr: {:.4e}'\n",
    "\n",
    "            print((fmt_str1 + fmt_str2).format(\n",
    "                epoch,\n",
    "                time.time() - time_,\n",
    "                train_ll,\n",
    "                val_ll,\n",
    "                lr))\n",
    "            \n",
    "            time_ = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_ll: 13.079126\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    test_ll = 0.\n",
    "    for i, x in enumerate(create_batcher(data.tst.x, batch_size=batch_size)):\n",
    "        x = torch.tensor(x, device=device)\n",
    "        ll = model(x)\n",
    "        test_ll += ll.detach().cpu().numpy()\n",
    "        \n",
    "    test_ll /= i * batch_size\n",
    "\n",
    "    print('test_ll: {:4f}'.format(test_ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_x = model.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sampled_x[:,0].cpu(), sampled_x[:,1].cpu(), s=1, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data.trn.x[:,0].cpu(), data.trn.x[:,1].cpu(), alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
